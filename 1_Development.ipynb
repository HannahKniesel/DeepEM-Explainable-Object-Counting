{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development \n",
    "\n",
    "## Image to Value(s)\n",
    "\n",
    "### Primary Focus: Explainable Object Counting in Microscopy Images\n",
    "### Application: Explainable Virus Capsid Quantification\n",
    "#### Challenge: Deep Learning as Black Box\n",
    "#### Required Labels: Location Labels\n",
    "\n",
    "\n",
    "TL;DR üß¨‚ú® We developed a regression model to quantify maturation states (\"naked\", \"budding\", \"enveloped\") of human cytomegalovirus (HCMV) during its final envelopment process i.e. secondary envelopment. Researchers can adapt the provided notebook for their own EM data analysis. \n",
    "\n",
    "![Teaser](./images/Teaser.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*By executing the cell below, we import external libraries, which simplify the implementation of the notebook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# imports from the template \n",
    "from deepEM.Utils import create_text_widget, print_info, print_error, print_warning, find_file, load_json, extract_defaults\n",
    "from deepEM.Logger import Logger\n",
    "from deepEM.ModelTuner import ModelTuner\n",
    "\n",
    "# costum implementation\n",
    "from src.ModelTrainer import ModelTrainer\n",
    "\n",
    "\n",
    "# import all required libraries\n",
    "from pathlib import Path \n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaults should be defined by DL expert\n",
    "\n",
    "default_datapath = \"data/tem-herpes/\"\n",
    "data_link=\"https://viscom-ulm.github.io/DeepEM/your-contribution.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to visualize a form.\n",
    "Within this form, you can decide what you'd like to do for the development of the model. You can choose from three options (or do all three):\n",
    "\n",
    "### 1. Hyperparameter Search\n",
    "**Hyperparameters** in deep learning are settings that determine how the model is trained. Unlike model parameters, which are learned from data, hyperparameters are set before training. Hyperparameter tuning involves exploring a range of hyperparameters by training the model multiple times and evaluating performance on a validation set. The best-performing hyperparameters are selected for further training.\n",
    "\n",
    "- **Hyperparameter search** is time- and resource-intensive. To reduce this, training runs are often limited to fewer epochs or smaller subsets of the data.\n",
    "- Our playground offers an automated **grid search** for hyperparameter tuning. The model is trained multiple times using all possible combinations of selected hyperparameters. \n",
    "- Deep learning (DL) experts define the search space and provide explanations for each parameter, enabling electron microscopy (EM) specialists to adjust it as needed.\n",
    "- The logging system provides estimates of the remaining time for a sweep, though these estimates can be inaccurate, especially at the beginning.\n",
    "\n",
    "While a hyperparameter search isn‚Äôt strictly required, it can significantly impact a model's performance. We strongly recommend performing it, especially when training with your own annotated data. Interrupting the search before it finishes may lead to suboptimal results.\n",
    "\n",
    "\n",
    "### 2. Model Training and Validation\n",
    "**Model Training and Validation** are key steps in developing a deep learning model. In this phase, the model is trained using the data you provide, and its performance is validated using a separate validation set. \n",
    "\n",
    "- **Training** involves feeding data to the model, adjusting weights based on the loss function, and iterating through multiple epochs to learn the optimal parameters.\n",
    "- **Validation** helps in assessing the model's performance on unseen data, which provides insights into how well it will generalize to new data. The validation set is crucial in preventing overfitting, ensuring the model does not memorize the training data but instead learns the underlying patterns.\n",
    "\n",
    "Choosing appropriate hyperparameters and training data are essential for successful training and validation. After the training phase, you can evaluate the model's performance to fine-tune further.\n",
    "\n",
    "### 3. Evaluation\n",
    "**Evaluation** is the final phase, where you test the model's performance after training. The evaluation phase involves assessing the model on a separate test set to determine its accuracy, precision, recall, or any other relevant metrics.\n",
    "\n",
    "- It provides an objective measurement of how well the model generalizes to new, unseen data.\n",
    "- During this phase, you may also perform error analysis to understand where the model performs well and where it fails.\n",
    "- Evaluation metrics are often used to compare the performance of different models or configurations, helping you select the best model for your needs.\n",
    "\n",
    "### Annotated Data Path\n",
    "Additionally, you need to define a **path to the annotated data** for model development. This data is essential for training, validating, and evaluating the model effectively. The data should be annotated according to the task you are working on (e.g., segmentation, classification).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2406eeb1934b5391c808d04dfd819d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepEM.EMDL_API import *\n",
    "\n",
    "with open(os.path.join(\"configs\",\"parameters.json\"), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# The shared data path widget (to be displayed once)\n",
    "input_data_path_shared = widgets.Text(description=\"Data Path:\", placeholder=\"Enter path...\", value=default_datapath, continuous_update=False)\n",
    "datapath_explanation = widgets.HTML(f\"<p>If you want to use your own data for model development please define the path to this folder here. For details about how to collect, annotate and preprocess your own dataset for model development please see <a href={data_link}>here.</a></p><hr>\")\n",
    "\n",
    "\n",
    "# ---------- Hyperparameter Search ----------\n",
    "checkbox_hyperparam = widgets.Checkbox(description=\"‚öôÔ∏è Hyperparameter Search\", style={\"description_width\": \"0px\"})\n",
    "html_hyperparam_explanation = widgets.HTML(\"<p>Select if you want to do a hyperparameter search. This is recommended before training a model, but requires lots of compute and resources, as multiple training runs are done to select the best set of hyperparameters.</p><hr>\")\n",
    "\n",
    "radio_search_type = widgets.RadioButtons(\n",
    "    options=['Default Search', 'Custom Search'], \n",
    "    description='Search Type:', \n",
    "    disabled=False\n",
    ")\n",
    "html_radio_search_type_explanation = widgets.HTML(\"<i>Select whether to use the default search space, defined by the DL expert, or a custom search space for hyperparameter tuning.</i>\")\n",
    "\n",
    "form_custom_hyperparam, input_widgets = create_hyperparameter_widgets(config)\n",
    "#widgets.Textarea(description=\"Custom Hyperparams:\", placeholder=\"Enter values...\")\n",
    "html_custom_hyperparam_explanation = widgets.HTML(\"<p>For defining parameters to check during the hyperparameter sweep separate them with a comma. Floating-point values should be written as `0.1`</p>\")\n",
    "\n",
    "# Group hyperparameter widgets with layout and background color\n",
    "hyperparam_container = widgets.VBox([\n",
    "    html_radio_search_type_explanation,\n",
    "    radio_search_type, \n",
    "], layout=widgets.Layout(\n",
    "    border=\"1px solid black\", \n",
    "    padding=\"10px\", \n",
    "    margin=\"10px\", \n",
    "    background_color=\"lightblue\"\n",
    "))\n",
    "\n",
    "# ---------- Training + Validation ----------\n",
    "checkbox_training = widgets.Checkbox(description=\"üìä Training + Validation\", style={\"description_width\": \"0px\"})\n",
    "html_training_explanation = widgets.HTML(\"<p>Select if you'd like to train and validate a model.</p><hr>\")\n",
    "\n",
    "# html_selected_hyperparams = widgets.HTML(\"<b>Currently selected hyperparameters: Default</b>\")\n",
    "html_selected_hyperparams = edit_hyperparameters(input_data_path_shared.value)\n",
    "checkbox_resume_training = widgets.Checkbox(description=\"Resume Training\")\n",
    "html_resume_training_explanation = widgets.HTML(\"<i>Select 'Resume Training' to load a previously saved model and continue training.</i>\")\n",
    "\n",
    "input_resume_model_path = widgets.Text(description=\"Model Path:\", placeholder=\"Enter model path...\")\n",
    "html_resume_model_path_explanation = widgets.HTML(\"<i>Provide the path to the model checkpoint to resume training.</i>\")\n",
    "\n",
    "# Group training widgets with layout and background color\n",
    "training_container = widgets.VBox([\n",
    "    html_resume_training_explanation,\n",
    "    checkbox_resume_training,\n",
    "], layout=widgets.Layout(\n",
    "    border=\"1px solid black\", \n",
    "    padding=\"10px\", \n",
    "    margin=\"10px\", \n",
    "    background_color=\"lightgreen\"\n",
    "))\n",
    "\n",
    "# ---------- Evaluation ----------\n",
    "checkbox_evaluation = widgets.Checkbox(description=\"üßê Evaluation\", style={\"description_width\": \"0px\"})\n",
    "html_checkbox_evaluation_explanation = widgets.HTML(\"<i>Select 'Evaluation' to evaluate your model on a test dataset.</i><hr>\")\n",
    "\n",
    "input_model_path_eval = widgets.Text(description=\"Model Path:\", placeholder=\"Enter path...\")\n",
    "html_model_path_eval_explanation = widgets.HTML(\"<i>Provide the path to the model checkpoint you want to evaluate.</i>\")\n",
    "\n",
    "slider_data_split = widgets.FloatSlider(description=\"Data Split\", min=0.1, max=1.0, step=0.1, value=0.2)\n",
    "html_slider_data_split_explanation = widgets.HTML(\"<i>Select the proportion of the data to use for evaluation (default is 0.2).</i>\")\n",
    "\n",
    "# Group evaluation widgets with layout and background color\n",
    "evaluation_container = widgets.VBox([\n",
    "    checkbox_evaluation,\n",
    "    input_model_path_eval, \n",
    "    html_model_path_eval_explanation,\n",
    "    slider_data_split,\n",
    "    html_slider_data_split_explanation\n",
    "], layout=widgets.Layout(\n",
    "    border=\"1px solid black\", \n",
    "    padding=\"10px\", \n",
    "    margin=\"10px\", \n",
    "    background_color=\"lightyellow\"\n",
    "))\n",
    "\n",
    "# ---------- Dynamic Display Update ----------\n",
    "output = widgets.Output()\n",
    "import threading\n",
    "\n",
    "# Debounce function\n",
    "def debounce_update(change):\n",
    "    global debounce_timer\n",
    "    if debounce_timer:\n",
    "        debounce_timer.cancel()  # Cancel previous timer\n",
    "\n",
    "    # Start a new timer with 0.5s delay\n",
    "    debounce_timer = threading.Timer(0.5, update_hyperparams)\n",
    "    debounce_timer.start()\n",
    "\n",
    "\n",
    "\n",
    "def update_resume(change):\n",
    "    # Check if Resume Training is selected and update the container dynamically\n",
    "    if checkbox_resume_training.value:\n",
    "        # Add Model Path input to training container dynamically if not already added\n",
    "        if input_resume_model_path not in training_container.children:\n",
    "            training_container.children = list(training_container.children) + [input_resume_model_path]\n",
    "    else:\n",
    "        # Remove Model Path input if Resume Training is deselected\n",
    "        if input_resume_model_path in training_container.children:\n",
    "            training_container.children = [child for child in training_container.children if child != input_resume_model_path]\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "def update_ui(change):\n",
    "    with output:\n",
    "        clear_output()\n",
    "\n",
    "        # Display shared Data Path widget only once if Hyperparameter Search, Training, or Evaluation is selected\n",
    "        display(input_data_path_shared, datapath_explanation)\n",
    "        \n",
    "        # Hyperparameter Search\n",
    "        if checkbox_hyperparam.value:\n",
    "            display(checkbox_hyperparam, hyperparam_container, html_hyperparam_explanation)\n",
    "            \n",
    "            \n",
    "            # Check if Custom Search is selected and update the container dynamically\n",
    "            if radio_search_type.value == 'Custom Search':\n",
    "                # Add custom search form to hyperparameter section dynamically if not already added\n",
    "                if form_custom_hyperparam not in hyperparam_container.children:\n",
    "                    hyperparam_container.children = list(hyperparam_container.children) + [html_custom_hyperparam_explanation, form_custom_hyperparam]\n",
    "            else:\n",
    "                # Remove custom search form if Default Search is selected\n",
    "                if form_custom_hyperparam in hyperparam_container.children:\n",
    "                    hyperparam_container.children = [child for child in hyperparam_container.children if child != form_custom_hyperparam]\n",
    "                    hyperparam_container.children = [child for child in hyperparam_container.children if child != html_custom_hyperparam_explanation]            \n",
    "        else: \n",
    "            display(checkbox_hyperparam, html_hyperparam_explanation)\n",
    "\n",
    "        # Training + Validation\n",
    "        if checkbox_training.value:\n",
    "            display(checkbox_training, training_container, html_training_explanation)\n",
    "            \n",
    "            if(not checkbox_hyperparam.value):\n",
    "                training_container.children = [html_selected_hyperparams] + list(training_container.children) \n",
    "            else: \n",
    "                training_container.children = [child for child in training_container.children if child != html_selected_hyperparams]\n",
    "\n",
    "            \n",
    "            \n",
    "        else: \n",
    "            display(checkbox_training, html_training_explanation)\n",
    "            training_container.children = [child for child in training_container.children if child != html_selected_hyperparams]\n",
    "\n",
    "        # Evaluation\n",
    "        if checkbox_evaluation.value:\n",
    "            # If Training is selected, hide Model Path and Data Split input for Evaluation\n",
    "            if checkbox_training.value:\n",
    "                evaluation_container.children = []  # Remove all elements from evaluation container\n",
    "            else:\n",
    "                # Show both Model Path and Data Split slider if Training is not selected\n",
    "                evaluation_container.children = [input_model_path_eval, html_model_path_eval_explanation, slider_data_split, html_slider_data_split_explanation]\n",
    "            display(checkbox_evaluation, evaluation_container, html_checkbox_evaluation_explanation)\n",
    "        else: \n",
    "            display(checkbox_evaluation, html_checkbox_evaluation_explanation)\n",
    "            \n",
    "def update_hyperparams(change=None):\n",
    "    global html_selected_hyperparams\n",
    "    # Recompute html_selected_hyperparams whenever input_data_path_shared changes\n",
    "    training_container.children = [child for child in training_container.children if child != html_selected_hyperparams]\n",
    "    html_selected_hyperparams = edit_hyperparameters(input_data_path_shared.value)\n",
    "    update_ui(None)  # Refresh UI to reflect changes\n",
    "\n",
    "# Initialize the selected hyperparameters\n",
    "update_hyperparams(None)    \n",
    "    \n",
    "\n",
    "# Attach event listeners\n",
    "checkbox_hyperparam.observe(update_ui, names=\"value\")\n",
    "radio_search_type.observe(update_ui, names=\"value\")\n",
    "checkbox_training.observe(update_ui, names=\"value\")\n",
    "checkbox_resume_training.observe(update_resume, names=\"value\")\n",
    "checkbox_evaluation.observe(update_ui, names=\"value\")\n",
    "input_data_path_shared.observe(update_hyperparams, names=\"value\")\n",
    "\n",
    "# Initial Display\n",
    "update_ui(None)\n",
    "display(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 15:08:44,640 - INFO - Hyperparameters saved to logs/tem-herpes_2025-03-26_15-08-44/TrainingRun/hyperparameters.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]::Data path was set to: data/tem-herpes/\n",
      "Logger initialized. Logs will be saved to: logs/tem-herpes_2025-03-26_15-08-44\n",
      "[INFO]::Will use following hyperparameters for future training: {'learning_rate': 0.0001, 'batch_size': 16}\n",
      "Logger initialized. Logs will be saved to: logs/tem-herpes_2025-03-26_15-08-44/TrainingRun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/hansel/SSD/Code/PaulFestschrift/Deep-EM Playground/DeepEM-Explainable-Object-Counting/src/Model.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(\n",
      "2025-03-26 15:08:47,663 - ERROR - Cound not find a trained model at logs/tem-herpes_2025-03-26_15-08-44/TrainingRun/checkpoints/best_model.pth. Make sure you fully train a model first before evaluating.\n",
      "2025-03-26 15:08:47,664 - ERROR - Cound not find a trained model for dataset 'data/tem-herpes/' at 'logs/tem-herpes_2025-03-26_15-08-44/TrainingRun/checkpoints/best_model.pth'. Make sure you train a model first before evaluating.\n"
     ]
    }
   ],
   "source": [
    "# Set data path\n",
    "data_path = input_data_path_shared.value\n",
    "if(not os.path.isdir(data_path)):\n",
    "    print_error(f\" Please check the provided Data Path for model development. Data Path {data_path} is not a directory.\")\n",
    "if(not os.listdir(data_path)):\n",
    "    print_error(f\" Please check the provided Data Path for model development. Data Path {data_path} is empty.\")\n",
    "print(f\"[INFO]::Data path was set to: {data_path}\")\n",
    "logger = Logger(data_path)\n",
    "model_trainer = ModelTrainer(data_path, logger)\n",
    "\n",
    "\n",
    "# hyperparameter search\n",
    "do_sweep = checkbox_hyperparam.value\n",
    "hyperparameter_tuner = ModelTuner(model_trainer, data_path, logger)\n",
    "best_config = None\n",
    "if(do_sweep):\n",
    "    sweep_config = update_config(config, input_widgets)\n",
    "    hyperparameter_tuner.update_config(sweep_config)\n",
    "    best_config = hyperparameter_tuner.tune()\n",
    "\n",
    "\n",
    "# train model\n",
    "if(not best_config):\n",
    "    best_config = hyperparameter_tuner.update_hyperparameters(html_selected_hyperparams)\n",
    "    print_info(f\"Will use following hyperparameters for future training: {best_config}\")    \n",
    "resume_training = None\n",
    "if checkbox_resume_training.value:\n",
    "    resume_training = input_resume_model_path.value\n",
    "if(resume_training):\n",
    "    resume_training = Path(resume_training)\n",
    "    if(resume_training.is_dir()):\n",
    "        resume_training = find_file(resume_training, \"latest_model.pth\")\n",
    "    if(not resume_training.is_file()):\n",
    "        logger.log_error(f\"Could not find resume path at {resume_training}. Will start training from scatch.\")\n",
    "        resume_training = None\n",
    "logger.init(\"TrainingRun\")\n",
    "model_trainer.resume_from_checkpoint = resume_training\n",
    "model_trainer.prepare(best_config)\n",
    "if(checkbox_training.value):\n",
    "    model_trainer.fit()\n",
    "\n",
    "# Evaluation\n",
    "if(checkbox_evaluation.value):\n",
    "    start_evaluation = False\n",
    "    eval_model = input_model_path_eval.value\n",
    "    if(eval_model):\n",
    "        eval_model = Path(eval_model)\n",
    "        if(eval_model.is_dir()):\n",
    "            eval_model = Path(find_file(eval_model, \"best_model.pth\")) \n",
    "        if(not eval_model.is_file()):\n",
    "            logger.log_error(f\"Could not find model at {eval_model}. Make sure to train a model before evaluation.\")\n",
    "            eval_model = None\n",
    "        else: \n",
    "            start_evaluation = True\n",
    "    else:\n",
    "        recent_logs = logger.get_most_recent_logs()\n",
    "        eval_model = \"\"\n",
    "        for dataname, log_path in recent_logs.items():\n",
    "            if(dataname == Path(data_path).stem):\n",
    "                eval_model = Path(log_path+\"/TrainingRun/checkpoints/best_model.pth\")\n",
    "                if(not eval_model.is_file()):\n",
    "                    logger.log_error(f\"Cound not find a trained model at {eval_model}. Make sure you fully train a model first before evaluating.\")\n",
    "                else:\n",
    "                    logger.log_info(f\"Found most recent log at {eval_model}\")\n",
    "                    start_evaluation = True\n",
    "            else: \n",
    "                continue\n",
    "        if(not start_evaluation):\n",
    "            logger.log_error(f\"Cound not find a trained model for dataset '{data_path}' at '{eval_model}'. Make sure you train a model first before evaluating.\")\n",
    "        \n",
    "    if(start_evaluation):\n",
    "        model_trainer.load_checkpoint(eval_model)\n",
    "        model_trainer.test()      \n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-to-value",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
